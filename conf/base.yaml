dataroot:         ???               # path to images (should have subfolders trainA, trainB, valA, valB, etc
name:             'experiment_name' # name of the experiment. It decides where to store samples and models
gpu_ids:          ''               # gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU
checkpoints_dir:  './checkpoints'   # models are saved here
dataset_mode:     'unaligned'       # chooses how datasets are loaded. [unaligned | aligned | single | colorization]
direction:        'AtoB'            # AtoB or BtoA
serial_batches:   false             # if true, takes images in order to make batches, otherwise takes them randomly
num_threads:      4                 # # threads for loading data
batch_size:       1                 # input batch size
crop_size:        256               # then crop to this size
load_size:        286               # scale images to this size
max_dataset_size: 99999999          # Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.
preprocess:       'resize_and_crop' # scaling and cropping of images at load time [resize_and_crop | crop | scale_width | scale_width_and_crop | none]
no_flip:          false             #  if specified, do not flip the images for data augmentation
display_id:       0
display_ncols:    4                 # if positive, display all images in a single visdom web panel with certain number of images per row.
display_winsize:  256               # display window size for both visdom and HTML
input_nc:         3                 # # of input image channels: 3 for RGB and 1 for grayscale
output_nc:        3                 # # of output image channels: 3 for RGB and 1 for grayscale
ngf:              64                # # of gen filters in the last conv layer
ndf:              64                # # of discrim filters in the first conv layer
netD:             'basic'           # specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator
netG:             'resnet_9blocks'  # specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128]
n_layers_D:       3                 # only used if netD==n_layers
norm:             'instance'        # instance normalization or batch normalization [instance | batch | none]
init_type:        'normal'          # network initialization [normal | xavier | kaiming | orthogonal]
init_gain:        0.02              # scaling factor for normal, xavier and orthogonal.
no_dropout:       false             # no dropout for the generator
epoch:            'latest'          # which epoch to load? set to latest to use latest cached model
load_iter:        0                 # which iteration to load? if load_iter > 0, the code will load models by iter_[load_iter]; otherwise, the code will load models by [epoch]
verbose:          false             # if specified, print more debugging information
suffix:           ''                # customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{load_size}
output_dir:       './outputs'
color_spaces:                       # DStretch Color spaces
  - 'lds'
